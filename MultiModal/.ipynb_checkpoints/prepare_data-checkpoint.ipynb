{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Raw Data\n",
    "df = pd.read_csv(\"../Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   Product_ID  User_ID  Time_ID  \n",
       "0           0        0        0  \n",
       "1           1        1        1  \n",
       "2           2        2        2  \n",
       "3           3        3        3  \n",
       "4           4        4        4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert str into ID\n",
    "df['Product_ID'] = pd.Categorical(df['ProductId'], categories=df['ProductId'].unique()).codes\n",
    "df['User_ID'] = pd.Categorical(df['UserId'], categories=df['UserId'].unique()).codes\n",
    "df['Time_ID'] = pd.Categorical(df['Time'], categories=df['Time'].unique()).codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   Product_ID  User_ID  Time_ID  \\\n",
       "0           0        0        0   \n",
       "1           1        1        1   \n",
       "2           2        2        2   \n",
       "3           3        3        3   \n",
       "4           4        4        4   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  i bought sever vital can dog food product foun...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  this confect around centuri it light pillowi c...  \n",
       "3  if look secret ingredi robitussin i believ i f...  \n",
       "4  great taffi great price there wide assort yumm...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Text\n",
    "df['CleanedText'] = df['Text'].replace(to_replace=r'@\\S+',value=\"\",regex=True)\n",
    "df[\"CleanedText\"] = df['CleanedText'].replace(to_replace=r'[^A-Za-z0-9]+',value=\" \",regex=True)\n",
    "df[\"CleanedText\"] = df[\"CleanedText\"].apply(lambda x: x.split())\n",
    "df[\"CleanedText\"] = df['CleanedText'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df['CleanedText'] = df['CleanedText'].apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "df['CleanedText'] = df['CleanedText'].apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  User_ID  Time_ID  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "0           0        0        0                     1                       1   \n",
       "1           1        1        1                     0                       0   \n",
       "2           2        2        2                     1                       1   \n",
       "3           3        3        3                     3                       3   \n",
       "4           4        4        4                     0                       0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         CleanedText  Score  \n",
       "0  i bought sever vital can dog food product foun...      5  \n",
       "1  product arriv label jumbo salt peanut peanut a...      1  \n",
       "2  this confect around centuri it light pillowi c...      4  \n",
       "3  if look secret ingredi robitussin i believ i f...      2  \n",
       "4  great taffi great price there wide assort yumm...      5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select specifical columns and drop the duplicates rows\n",
    "df1 = df[['Product_ID', 'User_ID', 'Time_ID', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Text', 'CleanedText', 'Score']].copy()\n",
    "df1 = df1.drop_duplicates(subset={\"Product_ID\",\"User_ID\",\"Time_ID\",\"CleanedText\"}, keep='first', inplace=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567107, 9)\n",
      "(568454, 14)\n"
     ]
    }
   ],
   "source": [
    "# See how many rows have been dropped\n",
    "print(df1.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "      <th>NormalizedHelpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  User_ID  Time_ID  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "0           0        0        0                     1                       1   \n",
       "1           1        1        1                     0                       0   \n",
       "2           2        2        2                     1                       1   \n",
       "3           3        3        3                     3                       3   \n",
       "4           4        4        4                     0                       0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         CleanedText  Score  \\\n",
       "0  i bought sever vital can dog food product foun...      5   \n",
       "1  product arriv label jumbo salt peanut peanut a...      1   \n",
       "2  this confect around centuri it light pillowi c...      4   \n",
       "3  if look secret ingredi robitussin i believ i f...      2   \n",
       "4  great taffi great price there wide assort yumm...      5   \n",
       "\n",
       "   NormalizedHelpfulness  \n",
       "0                      4  \n",
       "1                      1  \n",
       "2                      4  \n",
       "3                      5  \n",
       "4                      1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize helpness\n",
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def helpfulness(df):\n",
    "    numerator = df['HelpfulnessNumerator']\n",
    "    denominator = df['HelpfulnessDenominator']\n",
    "    \n",
    "    epsilon = 1e-5  # avoid zero denominators\n",
    "    df['NormalizedHelpfulness'] = 1 + (5 * sigmoid(df['HelpfulnessDenominator']) * df['HelpfulnessNumerator']/\n",
    "                                      (epsilon+df['HelpfulnessDenominator'])).apply(int)\n",
    "\n",
    "    return df  \n",
    "\n",
    "df1 = helpfulness(df1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51948, 9)\n",
      "(29751, 9)\n",
      "(42546, 9)\n",
      "(80536, 9)\n",
      "(362326, 9)\n"
     ]
    }
   ],
   "source": [
    "# split rows according to their 'Score'\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_diff_score = [0] * 5\n",
    "for i in range(5):\n",
    "    df_diff_score[i] = df1[df1['Score'] == i+1].copy()\n",
    "    df_diff_score[i] = shuffle(df_diff_score[i])\n",
    "    print(df_diff_score[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    20000\n",
       "4    20000\n",
       "3    20000\n",
       "2    20000\n",
       "1    20000\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate train_set and test_set\n",
    "\n",
    "df2 = pd.concat([df_diff_score[i][:20000] for i in range(5)])\n",
    "df2['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53091\n",
       "4    19759\n",
       "5    15646\n",
       "3     7629\n",
       "2     3875\n",
       "Name: NormalizedHelpfulness, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['NormalizedHelpfulness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53091, 9)\n",
      "(3875, 9)\n",
      "(7629, 9)\n",
      "(19759, 9)\n",
      "(15646, 9)\n"
     ]
    }
   ],
   "source": [
    "df_diff_help = [0] * 5\n",
    "for i in range(5):\n",
    "    df_diff_help[i] = df2[df2['NormalizedHelpfulness'] == i+1].copy()\n",
    "    df_diff_help[i] = shuffle(df_diff_help[i])\n",
    "    print(df_diff_help[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4632\n",
       "2    3876\n",
       "3    3411\n",
       "4    2827\n",
       "5    2754\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance Helpfulness\n",
    "\n",
    "df3 = pd.concat([df_diff_help[i][:3500] for i in range(5)])\n",
    "df3['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4632, 9)\n",
      "(3876, 9)\n",
      "(3411, 9)\n",
      "(2827, 9)\n",
      "(2754, 9)\n"
     ]
    }
   ],
   "source": [
    "df_diff_score = [0] * 5\n",
    "for i in range(5):\n",
    "    df_diff_score[i] = df3[df3['Score'] == i+1].copy()\n",
    "    df_diff_score[i] = shuffle(df_diff_score[i])\n",
    "    print(df_diff_score[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2700\n",
       "4    2700\n",
       "3    2700\n",
       "2    2700\n",
       "1    2700\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.concat([df_diff_score[i][:2700] for i in range(5)])\n",
    "df4['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2903\n",
       "5    2831\n",
       "4    2811\n",
       "3    2530\n",
       "2    2425\n",
       "Name: NormalizedHelpfulness, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['NormalizedHelpfulness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(train_set_number, test_set_number):\n",
    "    train_set = pd.concat([df_diff_score[i][:train_set_number] for i in range(5)])\n",
    "    test_set = pd.concat([df_diff_score[i][train_set_number:train_set_number+test_set_number] for i in range(5)])\n",
    "\n",
    "    train_set = shuffle(train_set)\n",
    "    test_set = shuffle(test_set)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = generate_dataset(2500, 200)\n",
    "local_train_set, local_test_set= generate_dataset(500, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    224\n",
       "5    213\n",
       "4    206\n",
       "3    205\n",
       "2    152\n",
       "Name: NormalizedHelpfulness, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['NormalizedHelpfulness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out raw ID, set them as Nan\n",
    "\n",
    "class MultiInput3:\n",
    "    def __init__(self, trainset, testset):\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "        \n",
    "        self.dic1 = self.Build_Dict('Product_ID')\n",
    "        self.dic2 = self.Build_Dict('User_ID')\n",
    "        self.dic3 = self.Build_Dict('Time_ID')\n",
    "    \n",
    "    # given feature string, return: dic\n",
    "    def Build_Dict(self, feature):\n",
    "        count = {}\n",
    "        data = list(self.trainset[feature].values) + list(self.testset[feature].values)\n",
    "\n",
    "        for item in data:\n",
    "            if not item in count:\n",
    "                count[item] = 1\n",
    "            else:\n",
    "                count[item] += 1\n",
    "\n",
    "        dic = {}\n",
    "        lens = 0\n",
    "        for item in count:\n",
    "            if count[item] <= 10:  # Nan \n",
    "                dic[item] = 0\n",
    "            else:\n",
    "                lens = lens + 1\n",
    "                dic[item] = lens\n",
    "\n",
    "        return dic\n",
    "\n",
    "def process_ID(df, MultiDict):\n",
    "    df['Normalized_Product_ID'] = df['Product_ID'].apply(lambda x: MultiDict.dic1[x])\n",
    "    df['Normalized_User_ID'] = df['User_ID'].apply(lambda x: MultiDict.dic2[x])\n",
    "    df['Normalized_Time_ID'] = df['Time_ID'].apply(lambda x: MultiDict.dic3[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Normalize_ID_train_test(train_set, test_set):\n",
    "    MultiDict = MultiInput3(train_set, test_set)\n",
    "    \n",
    "    train_set = process_ID(train_set, MultiDict)\n",
    "    test_set = process_ID(test_set, MultiDict)\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop out Rare Word and Map it to idea\n",
    "\n",
    "class CleanedTextDict:\n",
    "    def __init__(self, trainset, testset, max_len):\n",
    "        count_of_words = {}\n",
    "        words = (' '.join(list(trainset['CleanedText'].values) + list(testset['CleanedText'].values))).split()\n",
    "        \n",
    "        for word in words:\n",
    "            if not word in count_of_words:\n",
    "                count_of_words[word] = 1\n",
    "            else:\n",
    "                count_of_words[word] += 1\n",
    "        \n",
    "        self.dic = {}\n",
    "        self.VocabSize = 0\n",
    "        self.threshold = 10\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for word in count_of_words:\n",
    "            if count_of_words[word] <= 10: # Nan Threshold\n",
    "                continue\n",
    "            self.dic[word] = self.VocabSize\n",
    "            self.VocabSize += 1\n",
    "        \n",
    "        print(\"Cleaned Text Dict, Threshold = %d,  Vocab Size = %d\" % (self.threshold, self.VocabSize))\n",
    "    \n",
    "    def drop(self, s):\n",
    "        X = s.split()\n",
    "        X = [t for t in X if t in self.dic]\n",
    "        X = X[:max_len]\n",
    "        return ' '.join(X)\n",
    "\n",
    "    def toID(self, s):\n",
    "        X = s.split()\n",
    "        X = [self.dic[t] for t in X if t in self.dic]\n",
    "        return X\n",
    "    \n",
    "max_len = 128\n",
    "\n",
    "def DropRareWord(train_set, test_set):\n",
    "    TextDict = CleanedTextDict(train_set, test_set, max_len)\n",
    "    \n",
    "    train_set['MoreCleanedText'] = train_set['CleanedText'].apply(lambda x: TextDict.drop(x))\n",
    "    test_set['MoreCleanedText'] = test_set['CleanedText'].apply(lambda x: TextDict.drop(x))\n",
    "    \n",
    "    train_set['TextID'] = train_set['MoreCleanedText'].apply(lambda x: TextDict.toID(x))\n",
    "    test_set['TextID'] = test_set['MoreCleanedText'].apply(lambda x: TextDict.toID(x))\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get BERT TOKENS\n",
    "\n",
    "import bert\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "class BertTokenizer:\n",
    "    def __init__(self, max_len, bert_layer):\n",
    "        self.FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "        self.bert_layer = bert_layer\n",
    "        self.vocab_file = self.bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "        self.do_lower_case = self.bert_layer.resolved_object.do_lower_case.numpy()\n",
    "        self.tokenizer = self.FullTokenizer(self.vocab_file, self.do_lower_case)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def get_masks(self, tokens, max_len):\n",
    "        \"\"\"Mask for padding\"\"\"    \n",
    "        if len(tokens)>max_len:    \n",
    "            print(len(tokens))    \n",
    "            raise IndexError(\"Token length more than max seq length!\")    \n",
    "        return [1]*len(tokens) + [0] * (max_len - len(tokens)) \n",
    "\n",
    "    def get_segments(self, tokens, max_len):\n",
    "        \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "        if len(tokens)>max_len:\n",
    "            print(len(tokens))\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                current_segment_id = 1\n",
    "        return segments + [0] * (max_len - len(tokens))\n",
    "\n",
    "    def get_ids(self, tokens, tokenizer, max_len):\n",
    "        \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids = token_ids + [0] * (max_len-len(token_ids))\n",
    "        return input_ids\n",
    "\n",
    "    def GetStokens(self, s):\n",
    "        stokens = self.tokenizer.tokenize(s)\n",
    "        stokens = stokens[:self.max_len-2]\n",
    "        stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "\n",
    "        return stokens\n",
    "    \n",
    "    def GetInput_ids(self, stokens):\n",
    "        return self.get_ids(stokens, self.tokenizer, self.max_len)\n",
    "\n",
    "    def GetInput_masks(self, stokens):\n",
    "        return self.get_masks(stokens, self.max_len)\n",
    "    \n",
    "    def GetInput_segments(self, stokens):\n",
    "        return self.get_segments(stokens, self.max_len)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"../bert_layer\", trainable=False)\n",
    "tokenizer = BertTokenizer(max_len = max_len, bert_layer = bert_layer)\n",
    "\n",
    "def GetTokens(df):\n",
    "    df['stokens'] = df['MoreCleanedText'].apply(lambda x: tokenizer.GetStokens(x))\n",
    "    df['input_ids'] = df['stokens'].apply(lambda x: tokenizer.GetInput_ids(x))\n",
    "    df['input_masks'] = df['stokens'].apply(lambda x: tokenizer.GetInput_masks(x))\n",
    "    df['input_segments'] = df['stokens'].apply(lambda x: tokenizer.GetInput_segments(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text Dict, Threshold = 10,  Vocab Size = 4064\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-d44e4c1d7146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-d44e4c1d7146>\u001b[0m in \u001b[0;36mfeature\u001b[0;34m(train_set, test_set)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalize_ID_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropRareWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGetTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-e4fbbb1e6856>\u001b[0m in \u001b[0;36mDropRareWord\u001b[0;34m(train_set, test_set)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TextID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TextID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/google_camp/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4043\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-e4fbbb1e6856>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TextID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TextID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoreCleanedText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTextDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-e4fbbb1e6856>\u001b[0m in \u001b[0;36mtoID\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-e4fbbb1e6856>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ID' is not defined"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "\n",
    "def feature(train_set, test_set):\n",
    "    train_set, test_set = Normalize_ID_train_test(train_set, test_set)\n",
    "    train_set, test_set = DropRareWord(train_set, test_set)\n",
    "    train_set, test_set = GetTokens(train_set), GetTokens(test_set)\n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = feature(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train_set, local_test_set = feature(local_train_set, local_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "train_set.to_csv(r'data/train_set.csv', index=False)\n",
    "test_set.to_csv(r'data/test_set.csv', index=False)\n",
    "\n",
    "local_train_set.to_csv(r'data/local_train_set.csv', index=False)\n",
    "local_test_set.to_csv(r'data/local_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "      <th>NormalizedHelpfulness</th>\n",
       "      <th>Normalized_Product_ID</th>\n",
       "      <th>Normalized_User_ID</th>\n",
       "      <th>Normalized_Time_ID</th>\n",
       "      <th>MoreCleanedText</th>\n",
       "      <th>stokens</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>input_masks</th>\n",
       "      <th>input_segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194693</th>\n",
       "      <td>24831</td>\n",
       "      <td>119647</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Meow Mix wet food is great.  My cats get this ...</td>\n",
       "      <td>meow mix wet food great my cat get treat night...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mix wet food great my cat get treat night know...</td>\n",
       "      <td>[[CLS], mix, wet, food, great, my, cat, get, t...</td>\n",
       "      <td>[101, 4666, 4954, 2833, 2307, 2026, 4937, 2131...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74367</th>\n",
       "      <td>9269</td>\n",
       "      <td>95</td>\n",
       "      <td>923</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>I snack on these at work when I get hungry bet...</td>\n",
       "      <td>i snack work i get hungri lunch dinner it help...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i snack work i get hungri lunch dinner it help...</td>\n",
       "      <td>[[CLS], i, snack, work, i, get, hung, ##ri, lu...</td>\n",
       "      <td>[101, 1045, 19782, 2147, 1045, 2131, 5112, 308...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91282</th>\n",
       "      <td>11450</td>\n",
       "      <td>65586</td>\n",
       "      <td>1242</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>One bag of thoroughly dried ghost peppers roug...</td>\n",
       "      <td>one bag thorough dri ghost pepper rough size t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>one bag dri pepper rough size back instruct pe...</td>\n",
       "      <td>[[CLS], one, bag, dr, ##i, pepper, rough, size...</td>\n",
       "      <td>[101, 2028, 4524, 2852, 2072, 11565, 5931, 294...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229570</th>\n",
       "      <td>29294</td>\n",
       "      <td>134844</td>\n",
       "      <td>448</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Love these cookies! They are delicate and flav...</td>\n",
       "      <td>love cooki they delic flavor absolut favorit c...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love cooki they delic flavor absolut favorit c...</td>\n",
       "      <td>[[CLS], love, cook, ##i, they, del, ##ic, flav...</td>\n",
       "      <td>[101, 2293, 5660, 2072, 2027, 3972, 2594, 1489...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562668</th>\n",
       "      <td>73674</td>\n",
       "      <td>110765</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have a 33 pound 8 month old puppy who loves ...</td>\n",
       "      <td>i 33 pound 8 month old puppi love chew 50 pome...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i pound 8 month old puppi love chew 50 50 i su...</td>\n",
       "      <td>[[CLS], i, pound, 8, month, old, pup, ##pi, lo...</td>\n",
       "      <td>[101, 1045, 9044, 1022, 3204, 2214, 26781, 819...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_ID  User_ID  Time_ID  HelpfulnessNumerator  \\\n",
       "194693       24831   119647      323                     1   \n",
       "74367         9269       95      923                     2   \n",
       "91282        11450    65586     1242                     1   \n",
       "229570       29294   134844      448                     2   \n",
       "562668       73674   110765      595                     0   \n",
       "\n",
       "        HelpfulnessDenominator  \\\n",
       "194693                       1   \n",
       "74367                        2   \n",
       "91282                        5   \n",
       "229570                       2   \n",
       "562668                       0   \n",
       "\n",
       "                                                     Text  \\\n",
       "194693  Meow Mix wet food is great.  My cats get this ...   \n",
       "74367   I snack on these at work when I get hungry bet...   \n",
       "91282   One bag of thoroughly dried ghost peppers roug...   \n",
       "229570  Love these cookies! They are delicate and flav...   \n",
       "562668  I have a 33 pound 8 month old puppy who loves ...   \n",
       "\n",
       "                                              CleanedText  Score  \\\n",
       "194693  meow mix wet food great my cat get treat night...      4   \n",
       "74367   i snack work i get hungri lunch dinner it help...      4   \n",
       "91282   one bag thorough dri ghost pepper rough size t...      2   \n",
       "229570  love cooki they delic flavor absolut favorit c...      4   \n",
       "562668  i 33 pound 8 month old puppi love chew 50 pome...      1   \n",
       "\n",
       "        NormalizedHelpfulness  Normalized_Product_ID  Normalized_User_ID  \\\n",
       "194693                      4                      0                   0   \n",
       "74367                       5                      0                   0   \n",
       "91282                       1                      0                   0   \n",
       "229570                      5                      0                   0   \n",
       "562668                      1                      0                   0   \n",
       "\n",
       "        Normalized_Time_ID                                    MoreCleanedText  \\\n",
       "194693                   0  mix wet food great my cat get treat night know...   \n",
       "74367                    0  i snack work i get hungri lunch dinner it help...   \n",
       "91282                    0  one bag dri pepper rough size back instruct pe...   \n",
       "229570                   0  love cooki they delic flavor absolut favorit c...   \n",
       "562668                   0  i pound 8 month old puppi love chew 50 50 i su...   \n",
       "\n",
       "                                                  stokens  \\\n",
       "194693  [[CLS], mix, wet, food, great, my, cat, get, t...   \n",
       "74367   [[CLS], i, snack, work, i, get, hung, ##ri, lu...   \n",
       "91282   [[CLS], one, bag, dr, ##i, pepper, rough, size...   \n",
       "229570  [[CLS], love, cook, ##i, they, del, ##ic, flav...   \n",
       "562668  [[CLS], i, pound, 8, month, old, pup, ##pi, lo...   \n",
       "\n",
       "                                                input_ids  \\\n",
       "194693  [101, 4666, 4954, 2833, 2307, 2026, 4937, 2131...   \n",
       "74367   [101, 1045, 19782, 2147, 1045, 2131, 5112, 308...   \n",
       "91282   [101, 2028, 4524, 2852, 2072, 11565, 5931, 294...   \n",
       "229570  [101, 2293, 5660, 2072, 2027, 3972, 2594, 1489...   \n",
       "562668  [101, 1045, 9044, 1022, 3204, 2214, 26781, 819...   \n",
       "\n",
       "                                              input_masks  \\\n",
       "194693  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "74367   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "91282   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "229570  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "562668  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           input_segments  \n",
       "194693  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "74367   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "91282   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "229570  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "562668  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Raw Data\n",
    "df = pd.read_csv(\"../Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   Product_ID  User_ID  Time_ID  \n",
       "0           0        0        0  \n",
       "1           1        1        1  \n",
       "2           2        2        2  \n",
       "3           3        3        3  \n",
       "4           4        4        4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert str into ID\n",
    "df['Product_ID'] = pd.Categorical(df['ProductId'], categories=df['ProductId'].unique()).codes\n",
    "df['User_ID'] = pd.Categorical(df['UserId'], categories=df['UserId'].unique()).codes\n",
    "df['Time_ID'] = pd.Categorical(df['Time'], categories=df['Time'].unique()).codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   Product_ID  User_ID  Time_ID  \\\n",
       "0           0        0        0   \n",
       "1           1        1        1   \n",
       "2           2        2        2   \n",
       "3           3        3        3   \n",
       "4           4        4        4   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  i bought sever vital can dog food product foun...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  this confect around centuri it light pillowi c...  \n",
       "3  if look secret ingredi robitussin i believ i f...  \n",
       "4  great taffi great price there wide assort yumm...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Text\n",
    "df['CleanedText'] = df['Text'].replace(to_replace=r'@\\S+',value=\"\",regex=True)\n",
    "df[\"CleanedText\"] = df['CleanedText'].replace(to_replace=r'[^A-Za-z0-9]+',value=\" \",regex=True)\n",
    "df[\"CleanedText\"] = df[\"CleanedText\"].apply(lambda x: x.split())\n",
    "df[\"CleanedText\"] = df['CleanedText'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df['CleanedText'] = df['CleanedText'].apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "df['CleanedText'] = df['CleanedText'].apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  User_ID  Time_ID  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "0           0        0        0                     1                       1   \n",
       "1           1        1        1                     0                       0   \n",
       "2           2        2        2                     1                       1   \n",
       "3           3        3        3                     3                       3   \n",
       "4           4        4        4                     0                       0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         CleanedText  Score  \n",
       "0  i bought sever vital can dog food product foun...      5  \n",
       "1  product arriv label jumbo salt peanut peanut a...      1  \n",
       "2  this confect around centuri it light pillowi c...      4  \n",
       "3  if look secret ingredi robitussin i believ i f...      2  \n",
       "4  great taffi great price there wide assort yumm...      5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select specifical columns and drop the duplicates rows\n",
    "df1 = df[['Product_ID', 'User_ID', 'Time_ID', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Text', 'CleanedText', 'Score']].copy()\n",
    "df1 = df1.drop_duplicates(subset={\"Product_ID\",\"User_ID\",\"Time_ID\",\"CleanedText\"}, keep='first', inplace=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567107, 9)\n",
      "(568454, 14)\n"
     ]
    }
   ],
   "source": [
    "# See how many rows have been dropped\n",
    "print(df1.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "      <th>NormalizedHelpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i bought sever vital can dog food product foun...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect around centuri it light pillowi c...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if look secret ingredi robitussin i believ i f...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there wide assort yumm...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_ID  User_ID  Time_ID  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "0           0        0        0                     1                       1   \n",
       "1           1        1        1                     0                       0   \n",
       "2           2        2        2                     1                       1   \n",
       "3           3        3        3                     3                       3   \n",
       "4           4        4        4                     0                       0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                         CleanedText  Score  \\\n",
       "0  i bought sever vital can dog food product foun...      5   \n",
       "1  product arriv label jumbo salt peanut peanut a...      1   \n",
       "2  this confect around centuri it light pillowi c...      4   \n",
       "3  if look secret ingredi robitussin i believ i f...      2   \n",
       "4  great taffi great price there wide assort yumm...      5   \n",
       "\n",
       "   NormalizedHelpfulness  \n",
       "0                      4  \n",
       "1                      1  \n",
       "2                      4  \n",
       "3                      5  \n",
       "4                      1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize helpness\n",
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def helpfulness(df):\n",
    "    numerator = df['HelpfulnessNumerator']\n",
    "    denominator = df['HelpfulnessDenominator']\n",
    "    \n",
    "    epsilon = 1e-5  # avoid zero denominators\n",
    "    df['NormalizedHelpfulness'] = 1 + (5 * sigmoid(df['HelpfulnessDenominator']) * df['HelpfulnessNumerator']/\n",
    "                                      (epsilon+df['HelpfulnessDenominator'])).apply(int)\n",
    "\n",
    "    return df  \n",
    "\n",
    "df1 = helpfulness(df1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51948, 9)\n",
      "(29751, 9)\n",
      "(42546, 9)\n",
      "(80536, 9)\n",
      "(362326, 9)\n"
     ]
    }
   ],
   "source": [
    "# split rows according to their 'Score'\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_diff_score = [0] * 5\n",
    "for i in range(5):\n",
    "    df_diff_score[i] = df1[df1['Score'] == i+1].copy()\n",
    "    df_diff_score[i] = shuffle(df_diff_score[i])\n",
    "    print(df_diff_score[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train_set and test_set\n",
    "\n",
    "def generate_dataset(train_set_number, test_set_number):\n",
    "    train_set = pd.concat([df_diff_score[i][:train_set_number] for i in range(5)])\n",
    "    test_set = pd.concat([df_diff_score[i][train_set_number:train_set_number+test_set_number] for i in range(5)])\n",
    "\n",
    "    train_set = shuffle(train_set)\n",
    "    test_set = shuffle(test_set)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = generate_dataset(5000, 500)\n",
    "local_train_set, local_test_set= generate_dataset(500, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5000\n",
       "4    5000\n",
       "3    5000\n",
       "2    5000\n",
       "1    5000\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out raw ID, set them as Nan\n",
    "\n",
    "class MultiInput3:\n",
    "    def __init__(self, trainset, testset):\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "        \n",
    "        self.dic1 = self.Build_Dict('Product_ID')\n",
    "        self.dic2 = self.Build_Dict('User_ID')\n",
    "        self.dic3 = self.Build_Dict('Time_ID')\n",
    "    \n",
    "    # given feature string, return: dic\n",
    "    def Build_Dict(self, feature):\n",
    "        count = {}\n",
    "        data = list(self.trainset[feature].values) + list(self.testset[feature].values)\n",
    "\n",
    "        for item in data:\n",
    "            if not item in count:\n",
    "                count[item] = 1\n",
    "            else:\n",
    "                count[item] += 1\n",
    "\n",
    "        dic = {}\n",
    "        lens = 0\n",
    "        for item in count:\n",
    "            if count[item] <= 10:  # Nan \n",
    "                dic[item] = 0\n",
    "            else:\n",
    "                lens = lens + 1\n",
    "                dic[item] = lens\n",
    "\n",
    "        return dic\n",
    "\n",
    "def process_ID(df, MultiDict):\n",
    "    df['Normalized_Product_ID'] = df['Product_ID'].apply(lambda x: MultiDict.dic1[x])\n",
    "    df['Normalized_User_ID'] = df['User_ID'].apply(lambda x: MultiDict.dic2[x])\n",
    "    df['Normalized_Time_ID'] = df['Time_ID'].apply(lambda x: MultiDict.dic3[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Normalize_ID_train_test(train_set, test_set):\n",
    "    MultiDict = MultiInput3(train_set, test_set)\n",
    "    \n",
    "    train_set = process_ID(train_set, MultiDict)\n",
    "    test_set = process_ID(test_set, MultiDict)\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop out Rare Word\n",
    "\n",
    "class CleanedTextDict:\n",
    "    def __init__(self, trainset, testset, max_len):\n",
    "        count_of_words = {}\n",
    "        words = (' '.join(list(trainset['CleanedText'].values) + list(testset['CleanedText'].values))).split()\n",
    "        \n",
    "        for word in words:\n",
    "            if not word in count_of_words:\n",
    "                count_of_words[word] = 1\n",
    "            else:\n",
    "                count_of_words[word] += 1\n",
    "        \n",
    "        self.dic = {}\n",
    "        self.VocabSize = 0\n",
    "        self.threshold = 10\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for word in count_of_words:\n",
    "            if count_of_words[word] <= 10: # Nan Threshold\n",
    "                continue\n",
    "            self.dic[word] = self.VocabSize\n",
    "            self.VocabSize += 1\n",
    "        \n",
    "        print(\"Cleaned Text Dict, Threshold = %d,  Vocab Size = %d\" % (self.threshold, self.VocabSize))\n",
    "    \n",
    "    def drop(self, s):\n",
    "        X = s.split()\n",
    "        X = [t for t in X if t in self.dic]\n",
    "        X = X[:max_len]\n",
    "        return ' '.join(X)\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "def DropRareWord(train_set, test_set):\n",
    "    TextDict = CleanedTextDict(train_set, test_set, max_len)\n",
    "    \n",
    "    train_set['MoreCleanedText'] = train_set['CleanedText'].apply(lambda x: TextDict.drop(x))\n",
    "    test_set['MoreCleanedText'] = test_set['CleanedText'].apply(lambda x: TextDict.drop(x))\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get BERT TOKENS\n",
    "\n",
    "import bert\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "class BertTokenizer:\n",
    "    def __init__(self, max_len, bert_layer):\n",
    "        self.FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "        self.bert_layer = bert_layer\n",
    "        self.vocab_file = self.bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "        self.do_lower_case = self.bert_layer.resolved_object.do_lower_case.numpy()\n",
    "        self.tokenizer = self.FullTokenizer(self.vocab_file, self.do_lower_case)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def get_masks(self, tokens, max_len):\n",
    "        \"\"\"Mask for padding\"\"\"    \n",
    "        if len(tokens)>max_len:    \n",
    "            print(len(tokens))    \n",
    "            raise IndexError(\"Token length more than max seq length!\")    \n",
    "        return [1]*len(tokens) + [0] * (max_len - len(tokens)) \n",
    "\n",
    "    def get_segments(self, tokens, max_len):\n",
    "        \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "        if len(tokens)>max_len:\n",
    "            print(len(tokens))\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                current_segment_id = 1\n",
    "        return segments + [0] * (max_len - len(tokens))\n",
    "\n",
    "    def get_ids(self, tokens, tokenizer, max_len):\n",
    "        \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids = token_ids + [0] * (max_len-len(token_ids))\n",
    "        return input_ids\n",
    "\n",
    "    def GetStokens(self, s):\n",
    "        stokens = self.tokenizer.tokenize(s)\n",
    "        stokens = stokens[:self.max_len-2]\n",
    "        stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "\n",
    "        return stokens\n",
    "    \n",
    "    def GetInput_ids(self, stokens):\n",
    "        return self.get_ids(stokens, self.tokenizer, self.max_len)\n",
    "\n",
    "    def GetInput_masks(self, stokens):\n",
    "        return self.get_masks(stokens, self.max_len)\n",
    "    \n",
    "    def GetInput_segments(self, stokens):\n",
    "        return self.get_segments(stokens, self.max_len)\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"./bert_layer\", trainable=False)\n",
    "tokenizer = BertTokenizer(max_len = max_len, bert_layer = bert_layer)\n",
    "\n",
    "def GetTokens(df):\n",
    "    df['stokens'] = df['MoreCleanedText'].apply(lambda x: tokenizer.GetStokens(x))\n",
    "    df['input_ids'] = df['stokens'].apply(lambda x: tokenizer.GetInput_ids(x))\n",
    "    df['input_masks'] = df['stokens'].apply(lambda x: tokenizer.GetInput_masks(x))\n",
    "    df['input_segments'] = df['stokens'].apply(lambda x: tokenizer.GetInput_segments(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text Dict, Threshold = 10, Vocab Size = 5418\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "\n",
    "def feature(train_set, test_set):\n",
    "    train_set, test_set = Normalize_ID_train_test(train_set, test_set)\n",
    "    train_set, test_set = DropRareWord(train_set, test_set)\n",
    "    train_set, test_set = GetTokens(train_set), GetTokens(test_set)\n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = feature(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text Dict, Threshold = 10, Vocab Size = 1597\n"
     ]
    }
   ],
   "source": [
    "local_train_set, local_test_set = feature(local_train_set, local_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "\n",
    "train_set.to_csv(r'data/train_set.csv', index=False)\n",
    "test_set.to_csv(r'data/test_set.csv', index=False)\n",
    "\n",
    "local_train_set.to_csv(r'data/local_train_set.csv', index=False)\n",
    "local_test_set.to_csv(r'data/local_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Time_ID</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "      <th>NormalizedHelpfulness</th>\n",
       "      <th>Normalized_Product_ID</th>\n",
       "      <th>Normalized_User_ID</th>\n",
       "      <th>Normalized_Time_ID</th>\n",
       "      <th>MoreCleanedText</th>\n",
       "      <th>stokens</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>input_masks</th>\n",
       "      <th>input_segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539237</th>\n",
       "      <td>70552</td>\n",
       "      <td>12568</td>\n",
       "      <td>1971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I typically feed them dry food, and once a day...</td>\n",
       "      <td>i typic feed dri food day i split fanci feast ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i typic feed dri food day i split fanci give t...</td>\n",
       "      <td>[[CLS], i, ty, ##pic, feed, dr, ##i, food, day...</td>\n",
       "      <td>[101, 1045, 5939, 24330, 5438, 2852, 2072, 283...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61336</th>\n",
       "      <td>7733</td>\n",
       "      <td>47905</td>\n",
       "      <td>1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are two pouches in each box.  The first,...</td>\n",
       "      <td>there two pouch box the first add water vodka ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there two pouch box the first add water desir ...</td>\n",
       "      <td>[[CLS], there, two, pouch, box, the, first, ad...</td>\n",
       "      <td>[101, 2045, 2048, 21445, 3482, 1996, 2034, 558...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398204</th>\n",
       "      <td>51457</td>\n",
       "      <td>71506</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I must admit, I didn't know what to expect.......</td>\n",
       "      <td>i must admit i know expect i order 24 sampl pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i must admit i know expect i order 24 sampl pa...</td>\n",
       "      <td>[[CLS], i, must, admit, i, know, expect, i, or...</td>\n",
       "      <td>[101, 1045, 2442, 6449, 1045, 2113, 5987, 1045...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249652</th>\n",
       "      <td>31820</td>\n",
       "      <td>6478</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Overall, this is a nice, light, refreshing dri...</td>\n",
       "      <td>overal nice light refresh drink the sweet bit ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>overal nice light refresh drink the sweet bit ...</td>\n",
       "      <td>[[CLS], over, ##al, nice, light, ref, ##resh, ...</td>\n",
       "      <td>[101, 2058, 2389, 3835, 2422, 25416, 21898, 43...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329111</th>\n",
       "      <td>42738</td>\n",
       "      <td>8076</td>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...I will drink this if all other coffee optio...</td>\n",
       "      <td>i drink coffe option exhaust the coffe vanilla...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i drink coffe option the coffe vanilla coconut...</td>\n",
       "      <td>[[CLS], i, drink, co, ##ffe, option, the, co, ...</td>\n",
       "      <td>[101, 1045, 4392, 2522, 16020, 5724, 1996, 252...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_ID  User_ID  Time_ID  HelpfulnessNumerator  \\\n",
       "539237       70552    12568     1971                     0   \n",
       "61336         7733    47905     1531                     0   \n",
       "398204       51457    71506     1440                     0   \n",
       "249652       31820     6478      168                     0   \n",
       "329111       42738     8076      759                     0   \n",
       "\n",
       "        HelpfulnessDenominator  \\\n",
       "539237                       0   \n",
       "61336                        0   \n",
       "398204                       0   \n",
       "249652                       1   \n",
       "329111                       0   \n",
       "\n",
       "                                                     Text  \\\n",
       "539237  I typically feed them dry food, and once a day...   \n",
       "61336   There are two pouches in each box.  The first,...   \n",
       "398204  I must admit, I didn't know what to expect.......   \n",
       "249652  Overall, this is a nice, light, refreshing dri...   \n",
       "329111  ...I will drink this if all other coffee optio...   \n",
       "\n",
       "                                              CleanedText  Score  \\\n",
       "539237  i typic feed dri food day i split fanci feast ...      3   \n",
       "61336   there two pouch box the first add water vodka ...      3   \n",
       "398204  i must admit i know expect i order 24 sampl pa...      1   \n",
       "249652  overal nice light refresh drink the sweet bit ...      4   \n",
       "329111  i drink coffe option exhaust the coffe vanilla...      1   \n",
       "\n",
       "        NormalizedHelpfulness  Normalized_Product_ID  Normalized_User_ID  \\\n",
       "539237                      1                      0                   0   \n",
       "61336                       1                      0                   0   \n",
       "398204                      1                      0                   0   \n",
       "249652                      1                      0                   0   \n",
       "329111                      1                      0                   0   \n",
       "\n",
       "        Normalized_Time_ID                                    MoreCleanedText  \\\n",
       "539237                   0  i typic feed dri food day i split fanci give t...   \n",
       "61336                    0  there two pouch box the first add water desir ...   \n",
       "398204                   0  i must admit i know expect i order 24 sampl pa...   \n",
       "249652                   0  overal nice light refresh drink the sweet bit ...   \n",
       "329111                   0  i drink coffe option the coffe vanilla coconut...   \n",
       "\n",
       "                                                  stokens  \\\n",
       "539237  [[CLS], i, ty, ##pic, feed, dr, ##i, food, day...   \n",
       "61336   [[CLS], there, two, pouch, box, the, first, ad...   \n",
       "398204  [[CLS], i, must, admit, i, know, expect, i, or...   \n",
       "249652  [[CLS], over, ##al, nice, light, ref, ##resh, ...   \n",
       "329111  [[CLS], i, drink, co, ##ffe, option, the, co, ...   \n",
       "\n",
       "                                                input_ids  \\\n",
       "539237  [101, 1045, 5939, 24330, 5438, 2852, 2072, 283...   \n",
       "61336   [101, 2045, 2048, 21445, 3482, 1996, 2034, 558...   \n",
       "398204  [101, 1045, 2442, 6449, 1045, 2113, 5987, 1045...   \n",
       "249652  [101, 2058, 2389, 3835, 2422, 25416, 21898, 43...   \n",
       "329111  [101, 1045, 4392, 2522, 16020, 5724, 1996, 252...   \n",
       "\n",
       "                                              input_masks  \\\n",
       "539237  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "61336   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "398204  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "249652  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "329111  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           input_segments  \n",
       "539237  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "61336   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "398204  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "249652  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "329111  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
